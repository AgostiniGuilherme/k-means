Clusteriza√ß√£o K-Means ‚Äì Iris Dataset

Este projeto implementa o algoritmo K-Means em Python, aplicado ao famoso dataset Iris, com duas vers√µes:

Implementa√ß√£o do zero (hardcore/scratch)

Implementa√ß√£o usando sklearn

O objetivo √© comparar qualidade e desempenho entre as duas abordagens.

üîé O que √© K-Means?

K-Means √© um algoritmo de aprendizado n√£o supervisionado usado para clustering (agrupamento) de dados. O objetivo √© dividir um conjunto em k grupos (clusters), onde cada ponto pertence ao cluster cujo centr√≥ide est√° mais pr√≥ximo.

Como funciona o algoritmo (vers√£o do zero):

Inicializa√ß√£o: Escolhe k centr√≥ides aleat√≥rios.

Atribui√ß√£o: Cada ponto √© associado ao centr√≥ide mais pr√≥ximo (dist√¢ncia euclidiana).

Atualiza√ß√£o: Os centr√≥ides s√£o recalculados como a m√©dia dos pontos do cluster.

Repeti√ß√£o: Os passos 2‚Äì3 s√£o repetidos at√© os centr√≥ides estabilizarem.

üìÇ Estrutura do C√≥digo
Implementa√ß√µes:

kmeans_iris_scratch.py ‚Üí Algoritmo implementado manualmente (puro NumPy).

kmeans_iris_sklearn.py ‚Üí Algoritmo usando sklearn.cluster.KMeans.

relatorio.txt ‚Üí Compara√ß√£o e an√°lise dos resultados.

Fun√ß√µes principais (scratch):

inicializar_centroides() ‚Üí Escolhe centr√≥ides iniciais.

atribuir_clusters() ‚Üí Calcula dist√¢ncias e define clusters.

atualizar_centroides() ‚Üí Recalcula centr√≥ides.

kmeans() ‚Üí Controla a execu√ß√£o at√© a converg√™ncia.

Dataset utilizado:

Iris Dataset: 150 amostras de flores √≠ris com 4 caracter√≠sticas:

Comprimento da s√©pala

Largura da s√©pala

Comprimento da p√©tala

Largura da p√©tala

(Obs: a vari√°vel target foi ignorada na clusteriza√ß√£o.)

‚ñ∂Ô∏è Como executar
Pr√©-requisitos:
pip install numpy scikit-learn

Execu√ß√£o:
# Vers√£o implementada do zero
python kmeans_iris_scratch.py

# Vers√£o sklearn
python kmeans_iris_sklearn.py

üìä Resultados gerados

Ambas as implementa√ß√µes executam os experimentos com k=3 e k=5 clusters e geram:

centroides_scratch_k*.npy / clusters_scratch_k*.npy

centroides_sklearn_k*.npy / clusters_sklearn_k*.npy

resultados_scratch.txt

resultados_sklearn.txt

M√©tricas avaliadas:

Silhouette Score (qualidade do clustering, -1 a 1, quanto maior melhor).

Tempo de execu√ß√£o (desempenho).

Resultados obtidos (exemplo real):
[Scratch] k=3 silhouette=0.5528 tempo=0.0088s
[Scratch] k=5 silhouette=0.4931 tempo=0.0024s

[Sklearn] k=3 silhouette=0.5528 tempo=3.3947s
[Sklearn] k=5 silhouette=0.4912 tempo=0.0481s

Interpreta√ß√£o:

O melhor valor foi k=3, que corresponde naturalmente √†s 3 esp√©cies do Iris.

A vers√£o scratch foi mais r√°pida (c√≥digo simples), mas menos robusta.

A vers√£o sklearn foi mais lenta (faz v√°rias inicializa√ß√µes por padr√£o), por√©m mais est√°vel.

üìå Conclus√£o

A implementa√ß√£o do zero refor√ßou o entendimento interno do K-Means.

O sklearn demonstrou melhor robustez e praticidade em aplica√ß√µes reais.

O PCA (n√£o mostrado aqui, mas dispon√≠vel nos scripts) permitiu visualizar os clusters em 1D e 2D, confirmando que k=3 √© a melhor escolha.